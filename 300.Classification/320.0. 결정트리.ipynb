{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결정 트리 무작정 해보기 - 붓꽃 데이터 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결정 트리 시각화 도구  - GraphViz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Graphviz 파일을 png로 전환하는 법(tree.dot ->tree.png)\n",
    "cmd창에서 다음 문장을 실행\n",
    "\n",
    "dot tree.dot -T png -o tree.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Decision Tree with dtreeviz Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install dtreeviz\n",
    "\n",
    "# 맥북에서 작동 안됨(설치는 되나 작동 안됨. 2023.02.07)\n",
    "from dtreeviz.trees import dtreeviz # remember to load the package\n",
    "\n",
    "viz = dtreeviz(dt, X_train, y_train,\n",
    "                target_name=\"target\",\n",
    "                feature_names=iris.feature_names,\n",
    "                class_names=iris.target_names)\n",
    "\n",
    "viz\n",
    "#to save files\n",
    "#viz.save(\"decision_tree.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 결정 트리 실습 1) 와인 데이터 - Kaggle 와인 데이터를 일부 활용하여 사용\n",
    "\n",
    "와인데이터 from Keggle\n",
    "0이면 레드와인, 1이면 화이트 -> 전체 와인 중 화이트와인을 골라낸다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wine_kaggle의 alcohol, residual_sugar, pH, style 데이터만 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과적합 모델\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결정트리와 과적합 및 규제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화 : plot_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot_tree()  트리 깊이 제한, 색깔 부여, 특성 이름 전달\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 가지치기 - 과적합 방지, (깊이 제한 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가지치기한 dt를 시각화\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 결정 트리에서 특성 스케일링 필요성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표준화 스케일링 하지 않은 DT 시각화 -> 이해하기 쉽다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 특성 중요도(feature_importances_)\n",
    "- 어떤 특성이 가장 유용한 특성인지 나타냄\n",
    "- feature_importances_  속성에 저장되어 있음\n",
    "\n",
    "- 특성 중요도 계산 원리: 각 노드의 정보 이득 * 전체 샘플에 대한 비율을 곱한 후 특성별로 더하여 계산함\n",
    "- 특성 중요도의 활용: 특성 선택에 활용(즉, 결정 트리 모델을 특성 선택에 활용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 결정 트리 실습 2) 붓꽃 데이터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결정 트리 비교: Iris, 꽃받침 정보(너비와 길이)로 결정 트리를 만들어 위의 경우와 비교하라"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Iris()로 결정트리를 만들면, 꽃잎(petal)의 길이와 너비만 분류기준으로 사용되고 꽃받침의 너비와 길이는 분류 기준으로 사용되지 않는다. \n",
    "iris의 꽃받침 정보는 처음 두 속성에 저장되어 있다. 꽃잎 정보를 버리고 꽃받침 정보만 사용하려면 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data[:, :2], iris.target,\n",
    "                                                   test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=3)\n",
    "dt.fit(X_train, y_train)\n",
    "print(dt.score(X_train, y_train))\n",
    "print(dt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1분이상 걸림\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(10, 7))\n",
    "plot_tree(dt, max_depth=3, filled=True, feature_names=iris.feature_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "꽃받침 정보만을 이용하여 결정 트리를 만들었을 경우 지나치게 많은 분할이 일어나며, 각 노드의 지니 불순도도 빠르게 감소시키지 못함. \n",
    "꽃받침 특성이 아닌 꽃잎(Petal) 속성이 더 잘 작동"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 참고: 엔트로피를 사용하여 결정트리 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data[:, :2], iris.target,\n",
    "                                                   test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=3, criterion='entropy')\n",
    "dt.fit(X_train, y_train)\n",
    "print(dt.score(X_train, y_train))\n",
    "print(dt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1분이상 걸림\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import plot_tree\n",
    "plt.figure(figsize=(10, 7))\n",
    "plot_tree(dt, max_depth=3, filled=True, feature_names=iris.feature_names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결정 트리 모델의 시각화(Decision Tree Visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Graphviz 패키지 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# DecisionTree Classifier 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "# 붓꽃 데이터를 로딩하고, 학습과 테스트 데이터 셋으로 분리\n",
    "iris_data = load_iris()\n",
    "X_train , X_test , y_train , y_test = train_test_split(iris_data.data, iris_data.target,\n",
    "                                                       test_size=0.2,  random_state=11)\n",
    "\n",
    "# DecisionTreeClassifer 학습. \n",
    "dt_clf.fit(X_train , y_train)\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# export_graphviz()의 호출 결과로 out_file로 지정된 tree.dot 파일을 생성함. \n",
    "dot_data = export_graphviz(dt_clf, out_file=None, class_names=iris_data.target_names , \\\n",
    "    feature_names = iris_data.feature_names, impurity=True, filled=True)\n",
    "\n",
    "import graphviz\n",
    "graph = graphviz.Source(dot_data, format=\"png\")\n",
    "graph\n",
    "\n",
    "# to save file\n",
    "# graph.render(\"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dtreeviz.trees import dtreeviz # remember to load the package\n",
    "\n",
    "viz = dtreeviz(dt_clf, iris.data, iris.target,\n",
    "                target_name=\"target\",\n",
    "                feature_names=iris.feature_names,\n",
    "                class_names=list(iris.target_names))\n",
    "\n",
    "viz\n",
    "\n",
    "#viz.save(\"decision_tree.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz.save(\"decision_tree.svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결정 트리의 중요한 역할 피처: feature_importances_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target,\n",
    "                                                   test_size=0.2, random_state=1)\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=3)\n",
    "dt.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      "[0.    0.    0.079 0.921]\n",
      "sepal length (cm) : 0.000\n",
      "sepal width (cm) : 0.000\n",
      "petal length (cm) : 0.079\n",
      "petal width (cm) : 0.921\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# feature importance 추출 \n",
    "print(\"Feature importances:\\n{0}\".format(np.round(dt.feature_importances_, 3)))\n",
    "\n",
    "# feature별 importance 매핑\n",
    "for name, value in zip(iris.feature_names , dt.feature_importances_):\n",
    "    print('{0} : {1:.3f}'.format(name, value))\n",
    "\n",
    "# feature importance를 column 별로 시각화 하기 \n",
    "sns.barplot(x=dt.feature_importances_ , y=iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결정 트리(Decision TREE) 과적합(Overfitting)\n",
    "- 결정트리는 규칙 생성 로직을 미리 제어하지 않으면 완벽하게 클래스 값을 구별해내기 위해 트리노드를 계속해서 만들어 가므로 매우 복잡한 트리가 만들어져 쉽게 과적합된다.\n",
    "\n",
    "- 결정트리 하이퍼파라미터 : 복잡한 트리 생성 방지 목적이 크다.\n",
    "\n",
    "* max_depth: 결정 트리 최대 깊이 제한\n",
    "* min_samples_split: 자식 노드를 분할하기 위한 최소한의 샘플데이터 수\n",
    "* min_samples_leaf: 리프 노드가 될 수 있는 샘플 데이터 건수의 최소값( 지정한 갯수 이하의 샘플만 리프 노드가 될 수 있다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 교차검증과 그리드 서치로 이동"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [실습] 타이타닉 데이터 결정트리 분류\n",
    "\n",
    "* 타이타닉 데이터를 결정트리 알고리듬에 따라 분류하고, 로지스틱 회귀와 평가지표를 비교하라"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######          여기까지 ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# DecisionTree Classifier 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "# 붓꽃 데이터를 로딩하고, 학습과 테스트 데이터 셋으로 분리\n",
    "iris_data = load_iris()\n",
    "X_train , X_test , y_train , y_test = train_test_split(iris_data.data, iris_data.target,\n",
    "                                                       test_size=0.2,  random_state=11)\n",
    "\n",
    "# DecisionTreeClassifer 학습. \n",
    "dt_clf.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "# export_graphviz()의 호출 결과로 out_file로 지정된 tree.dot 파일을 생성함. \n",
    "export_graphviz(dt_clf, out_file=\"tree.dot\", class_names=iris_data.target_names , \\\n",
    "feature_names = iris_data.feature_names, impurity=True, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "# 위에서 생성된 tree.dot 파일을 Graphviz 읽어서 Jupyter Notebook상에서 시각화 \n",
    "with open(\"tree.dot\") as f:\n",
    "    dot_graph = f.read()\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.title(\"3 Class values with 2 Features Sample data creation\")\n",
    "\n",
    "# 2차원 시각화를 위해서 feature는 2개, 결정값 클래스는 3가지 유형의 classification 샘플 데이터 생성. \n",
    "X_features, y_labels = make_classification(n_features=2, n_redundant=0, n_informative=2,\n",
    "                             n_classes=3, n_clusters_per_class=1,random_state=0)\n",
    "\n",
    "# plot 형태로 2개의 feature로 2차원 좌표 시각화, 각 클래스값은 다른 색깔로 표시됨. \n",
    "plt.scatter(X_features[:, 0], X_features[:, 1], marker='o', c=y_labels, s=25, cmap='rainbow', edgecolor='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Classifier의 Decision Boundary를 시각화 하는 함수\n",
    "def visualize_boundary(model, X, y):\n",
    "    fig,ax = plt.subplots()\n",
    "    \n",
    "    # 학습 데이타 scatter plot으로 나타내기\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, s=25, cmap='rainbow', edgecolor='k',\n",
    "               clim=(y.min(), y.max()), zorder=3)\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    xlim_start , xlim_end = ax.get_xlim()\n",
    "    ylim_start , ylim_end = ax.get_ylim()\n",
    "    \n",
    "    # 호출 파라미터로 들어온 training 데이타로 model 학습 . \n",
    "    model.fit(X, y)\n",
    "    # meshgrid 형태인 모든 좌표값으로 예측 수행. \n",
    "    xx, yy = np.meshgrid(np.linspace(xlim_start,xlim_end, num=200),np.linspace(ylim_start,ylim_end, num=200))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    \n",
    "    # contourf() 를 이용하여 class boundary 를 visualization 수행. \n",
    "    n_classes = len(np.unique(y))\n",
    "    contours = ax.contourf(xx, yy, Z, alpha=0.3,\n",
    "                           levels=np.arange(n_classes + 1) - 0.5,\n",
    "                           cmap='rainbow', clim=(y.min(), y.max()),\n",
    "                           zorder=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 특정한 트리 생성 제약없는 결정 트리의 Decsion Boundary 시각화.\n",
    "dt_clf = DecisionTreeClassifier().fit(X_features, y_labels)\n",
    "visualize_boundary(dt_clf, X_features, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# min_samples_leaf=6 으로 트리 생성 조건을 제약한 Decision Boundary 시각화\n",
    "dt_clf = DecisionTreeClassifier( min_samples_leaf=6).fit(X_features, y_labels)\n",
    "visualize_boundary(dt_clf, X_features, y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결정 트리 실습 - Human Activity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# features.txt 파일에는 피처 이름 index와 피처명이 공백으로 분리되어 있음. 이를 DataFrame으로 로드.\n",
    "feature_name_df = pd.read_csv('./human_activity/features.txt',sep='\\s+',\n",
    "                        header=None,names=['column_index','column_name'])\n",
    "\n",
    "# 피처명 index를 제거하고, 피처명만 리스트 객체로 생성한 뒤 샘플로 10개만 추출\n",
    "feature_name = feature_name_df.iloc[:, 1].values.tolist()\n",
    "print('전체 피처명에서 10개만 추출:', feature_name[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**중복된 피처명을 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dup_df = feature_name_df.groupby('column_name').count()\n",
    "print(feature_dup_df[feature_dup_df['column_index'] > 1].count())\n",
    "feature_dup_df[feature_dup_df['column_index'] > 1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**원본 데이터에 중복된 Feature 명으로 인하여 신규 버전의 Pandas에서 Duplicate name 에러를 발생.**  \n",
    "**중복 feature명에 대해서 원본 feature 명에 '_1(또는2)'를 추가로 부여하는 함수인 get_new_feature_name_df() 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_feature_name_df(old_feature_name_df):\n",
    "    feature_dup_df = pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(),\n",
    "                                  columns=['dup_cnt'])\n",
    "    feature_dup_df = feature_dup_df.reset_index()\n",
    "    new_feature_name_df = pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how='outer')\n",
    "    new_feature_name_df['column_name'] = new_feature_name_df[['column_name', 'dup_cnt']].apply(lambda x : x[0]+'_'+str(x[1]) \n",
    "                                                                                         if x[1] >0 else x[0] ,  axis=1)\n",
    "    new_feature_name_df = new_feature_name_df.drop(['index'], axis=1)\n",
    "    return new_feature_name_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_human_dataset( ):\n",
    "    \n",
    "    # 각 데이터 파일들은 공백으로 분리되어 있으므로 read_csv에서 공백 문자를 sep으로 할당.\n",
    "    feature_name_df = pd.read_csv('./human_activity/features.txt',sep='\\s+',\n",
    "                        header=None,names=['column_index','column_name'])\n",
    "    \n",
    "    # 중복된 피처명을 수정하는 get_new_feature_name_df()를 이용, 신규 피처명 DataFrame생성. \n",
    "    new_feature_name_df = get_new_feature_name_df(feature_name_df)\n",
    "    \n",
    "    # DataFrame에 피처명을 컬럼으로 부여하기 위해 리스트 객체로 다시 변환\n",
    "    feature_name = new_feature_name_df.iloc[:, 1].values.tolist()\n",
    "    \n",
    "    # 학습 피처 데이터 셋과 테스트 피처 데이터을 DataFrame으로 로딩. 컬럼명은 feature_name 적용\n",
    "    X_train = pd.read_csv('./human_activity/train/X_train.txt',sep='\\s+', names=feature_name )\n",
    "    X_test = pd.read_csv('./human_activity/test/X_test.txt',sep='\\s+', names=feature_name)\n",
    "    \n",
    "    # 학습 레이블과 테스트 레이블 데이터을 DataFrame으로 로딩하고 컬럼명은 action으로 부여\n",
    "    y_train = pd.read_csv('./human_activity/train/y_train.txt',sep='\\s+',header=None,names=['action'])\n",
    "    y_test = pd.read_csv('./human_activity/test/y_test.txt',sep='\\s+',header=None,names=['action'])\n",
    "    \n",
    "    # 로드된 학습/테스트용 DataFrame을 모두 반환 \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_human_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('## 학습 피처 데이터셋 info()')\n",
    "print(X_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train['action'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 예제 반복 시 마다 동일한 예측 결과 도출을 위해 random_state 설정\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "dt_clf.fit(X_train , y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , pred)\n",
    "print('결정 트리 예측 정확도: {0:.4f}'.format(accuracy))\n",
    "\n",
    "# DecisionTreeClassifier의 하이퍼 파라미터 추출\n",
    "print('DecisionTreeClassifier 기본 하이퍼 파라미터:\\n', dt_clf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    'max_depth' : [ 6, 8 ,10, 12, 16 ,20, 24]\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(dt_clf, param_grid=params, scoring='accuracy', cv=5, verbose=1 )\n",
    "grid_cv.fit(X_train , y_train)\n",
    "print('GridSearchCV 최고 평균 정확도 수치:{0:.4f}'.format(grid_cv.best_score_))\n",
    "print('GridSearchCV 최적 하이퍼 파라미터:', grid_cv.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV객체의 cv_results_ 속성을 DataFrame으로 생성. \n",
    "cv_results_df = pd.DataFrame(grid_cv.cv_results_)\n",
    "\n",
    "# max_depth 파라미터 값과 그때의 테스트(Evaluation)셋, 학습 데이터 셋의 정확도 수치 추출\n",
    "cv_results_df[['param_max_depth', 'mean_test_score']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = [ 6, 8 ,10, 12, 16 ,20, 24]\n",
    "# max_depth 값을 변화 시키면서 그때마다 학습과 테스트 셋에서의 예측 성능 측정\n",
    "for depth in max_depths:\n",
    "    dt_clf = DecisionTreeClassifier(max_depth=depth, random_state=156)\n",
    "    dt_clf.fit(X_train , y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test , pred)\n",
    "    print('max_depth = {0} 정확도: {1:.4f}'.format(depth , accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth' : [ 8 , 12, 16 ,20], \n",
    "    'min_samples_split' : [16,24],\n",
    "}\n",
    "\n",
    "grid_cv = GridSearchCV(dt_clf, param_grid=params, scoring='accuracy', cv=5, verbose=1 )\n",
    "grid_cv.fit(X_train , y_train)\n",
    "print('GridSearchCV 최고 평균 정확도 수치: {0:.4f}'.format(grid_cv.best_score_))\n",
    "print('GridSearchCV 최적 하이퍼 파라미터:', grid_cv.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?grid_cv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_df_clf = grid_cv.best_estimator_\n",
    "pred1 = best_df_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test , pred1)\n",
    "print('결정 트리 예측 정확도:{0:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "ftr_importances_values = best_df_clf.feature_importances_\n",
    "# Top 중요도로 정렬을 쉽게 하고, 시본(Seaborn)의 막대그래프로 쉽게 표현하기 위해 Series변환\n",
    "ftr_importances = pd.Series(ftr_importances_values, index=X_train.columns  )\n",
    "# 중요도값 순으로 Series를 정렬\n",
    "ftr_top20 = ftr_importances.sort_values(ascending=False)[:20]\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances Top 20')\n",
    "sns.barplot(x=ftr_top20 , y = ftr_top20.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "52ee2977380704a66854748a73250e0671a9318bd5b3fd45a3df9f851ae61629"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
